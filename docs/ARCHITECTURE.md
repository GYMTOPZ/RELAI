# RELAI Architecture Documentation

## ğŸ—ï¸ System Overview

RELAI is a full-stack web application that generates personalized AI videos for social media using multiple AI services.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ HTTPS
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  React Frontend â”‚ (Vite + TailwindCSS)
â”‚   Port: 3000    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ REST API
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI Backendâ”‚ (Python)
â”‚   Port: 8000    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â–º OpenAI Sora 2 API (Video Generation)
         â”œâ”€â”€â–º ElevenLabs API (Voice Generation)
         â”œâ”€â”€â–º Suno API (Music Generation)
         â””â”€â”€â–º OpenAI GPT-4 API (Suggestions)
```

---

## ğŸ“¦ Component Architecture

### Frontend Architecture

```
frontend/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.jsx              # App entry point
â”‚   â”œâ”€â”€ App.jsx               # Main application component
â”‚   â”œâ”€â”€ index.css             # Global styles
â”‚   â””â”€â”€ App.css               # Component styles
â”œâ”€â”€ public/                   # Static assets
â”œâ”€â”€ package.json              # Dependencies
â”œâ”€â”€ vite.config.js            # Vite configuration
â””â”€â”€ tailwind.config.js        # Tailwind configuration
```

#### Component Structure

```
App
â”œâ”€â”€ Header
â”œâ”€â”€ ImageUploadStep (step 1)
â”œâ”€â”€ PromptCreationStep (step 2)
â”‚   â”œâ”€â”€ PromptInput
â”‚   â”œâ”€â”€ SuggestionGenerator
â”‚   â”œâ”€â”€ VoiceSelector
â”‚   â””â”€â”€ GenerateButton
â”œâ”€â”€ GeneratingStep (step 3)
â”‚   â””â”€â”€ ProgressIndicator
â””â”€â”€ DownloadStep (step 4)
    â”œâ”€â”€ VideoPreview
    â””â”€â”€ DownloadButton
```

### Backend Architecture

```
backend/
â”œâ”€â”€ main.py                   # FastAPI app & routes
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ sora_service.py       # Video generation
â”‚   â”œâ”€â”€ voice_service.py      # Voice synthesis
â”‚   â”œâ”€â”€ music_service.py      # Music generation
â”‚   â””â”€â”€ suggestion_service.py # Content suggestions
â”œâ”€â”€ uploads/                  # User uploads (temp)
â””â”€â”€ generated_videos/         # Generated videos (temp)
```

#### Service Layer Pattern

Each service is independent and handles specific functionality:

```python
class SoraService:
    - generate_video()
    - get_video_status()
    - _enhance_prompt()
    - _monitor_video_generation()

class VoiceService:
    - generate_voice()
    - clone_voice()
    - get_available_voices()
    - _create_narration()

class MusicService:
    - generate_music()
    - _create_music_prompt()
    - _wait_for_music()

class SuggestionService:
    - generate_suggestions()
    - enhance_prompt()
    - _parse_suggestions()
```

---

## ğŸ”„ Data Flow

### Complete Video Generation Flow

```
1. User uploads image
   Frontend â†’ Backend /api/upload/image
   â””â”€â–º Saves to uploads/ directory
   â””â”€â–º Returns file_id

2. User creates prompt (optional: gets AI suggestions)
   Frontend â†’ Backend /api/suggestions/generate
   â””â”€â–º GPT-4 generates creative ideas
   â””â”€â–º Returns suggestions array

3. User clicks "Generate Video"
   Frontend â†’ Backend /api/video/generate
   â”œâ”€â–º SoraService.generate_video()
   â”‚   â”œâ”€â–º Reads user image
   â”‚   â”œâ”€â–º Enhances prompt
   â”‚   â””â”€â–º Calls Sora 2 API
   â”‚
   â”œâ”€â–º VoiceService.generate_voice() / clone_voice()
   â”‚   â”œâ”€â–º Creates narration script
   â”‚   â”œâ”€â–º Calls ElevenLabs API
   â”‚   â””â”€â–º Returns audio file
   â”‚
   â”œâ”€â–º MusicService.generate_music()
   â”‚   â”œâ”€â–º Determines music style
   â”‚   â”œâ”€â–º Calls Suno API
   â”‚   â””â”€â–º Returns music file
   â”‚
   â””â”€â–º Combines all (Sora 2 does this)
       â””â”€â–º Returns video_id

4. Frontend polls status
   Frontend â†’ Backend /api/video/status/{video_id}
   â””â”€â–º Checks generation status
   â””â”€â–º Returns: processing | completed | failed

5. Video ready
   Frontend â†’ Backend /api/video/download/{video_id}
   â””â”€â–º Returns video file (MP4)
```

---

## ğŸ—„ï¸ Data Models

### Request Models

```python
class VideoRequest(BaseModel):
    user_image_id: str          # UUID from upload
    prompt: str                 # Video description
    voice_type: str = "ai"      # "ai" or "custom"
    voice_file_id: Optional[str] = None
    duration: int = 30          # 15-60 seconds

class SuggestionRequest(BaseModel):
    context: str                # User context
    user_preferences: Optional[str] = None
```

### Response Models

```python
# Upload Response
{
    "file_id": "uuid",
    "filename": "photo.jpg",
    "message": "Image uploaded successfully"
}

# Video Generation Response
{
    "video_id": "uuid",
    "status": "processing",
    "message": "Video generation started"
}

# Video Status Response
{
    "status": "completed",
    "video_path": "/path/to/video.mp4",
    "sora_job_id": "sora-job-id",
    "prompt": "original prompt"
}

# Suggestions Response
{
    "suggestions": [
        {
            "title": "Video Title",
            "description": "Detailed description",
            "duration": 30,
            "platforms": ["TikTok", "Instagram"],
            "hashtags": ["#tag1", "#tag2"],
            "hook": "Opening description"
        }
    ]
}
```

---

## ğŸ”Œ API Integration Details

### Sora 2 API (OpenAI)

```python
# Video Generation Request
await client.videos.generate(
    model="sora-2.0",
    prompt=enhanced_prompt,
    image=image_data,           # User's photo
    duration=30,
    resolution="1080p",
    fps=30,
    audio={
        "voice": voice_data,    # From ElevenLabs
        "music": music_data     # From Suno
    }
)

# Response
{
    "id": "job_id",
    "status": "processing",
    "output": {
        "url": "video_url"      # When completed
    }
}
```

### ElevenLabs API

```python
# Voice Generation
await client.text_to_speech.convert(
    voice_id="voice_id",
    text=narration_text,
    model_id="eleven_multilingual_v2",
    voice_settings={
        "stability": 0.5,
        "similarity_boost": 0.75
    }
)

# Voice Cloning
await client.voices.add(
    name="user_voice",
    files=[voice_sample_data]
)
```

### Suno API

```python
# Music Generation
POST https://api.suno.ai/v1/generate
{
    "prompt": "energetic gym workout music",
    "duration": 30,
    "instrumental": true,
    "style": "modern"
}

# Response
{
    "id": "generation_id",
    "status": "processing",
    "audio_url": "url"  # When completed
}
```

### GPT-4 API (Suggestions)

```python
# Content Suggestions
await client.chat.completions.create(
    model="gpt-4-turbo-preview",
    messages=[
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ],
    temperature=0.8
)
```

---

## ğŸ” Security Architecture

### Authentication Flow (Future)

```
User â†’ JWT Token â†’ Backend â†’ Verify â†’ Allow/Deny
```

### File Upload Security

```python
1. Validate file type
2. Check file size (< 10MB)
3. Generate unique UUID filename
4. Scan for malware (future)
5. Store temporarily
6. Clean up after video generation
```

### API Key Management

```
Environment Variables â†’ Backend Only
- Never exposed to frontend
- Loaded from .env
- Not committed to git
```

---

## ğŸ“Š State Management

### Frontend State

```javascript
// App.jsx manages all state
const [step, setStep] = useState(1)              // Current step
const [userImage, setUserImage] = useState(null) // Image preview
const [userImageId, setUserImageId] = useState(null) // Backend ID
const [prompt, setPrompt] = useState('')         // User prompt
const [voiceType, setVoiceType] = useState('ai') // Voice option
const [videoId, setVideoId] = useState(null)     // Generated video ID
const [videoStatus, setVideoStatus] = useState(null) // Generation status
```

### Backend State

```python
# In-memory storage (current)
self.video_jobs = {
    "video_id": {
        "status": "processing",
        "sora_job_id": "job_id",
        "prompt": "original prompt"
    }
}

# Future: Database storage
- PostgreSQL for persistence
- Redis for caching
- S3/R2 for file storage
```

---

## ğŸš€ Performance Considerations

### Caching Strategy

```
1. Frontend
   - Image preview cached locally
   - Suggestions cached in state

2. Backend (Future)
   - Redis for API responses
   - CDN for generated videos
   - Database query caching
```

### Async Processing

```python
# Video generation runs in background
asyncio.create_task(self._monitor_video_generation(video_id))

# Frontend polls for status (every 5 seconds)
const interval = setInterval(async () => {
    const status = await checkVideoStatus(videoId)
}, 5000)
```

---

## ğŸ“ File Storage Strategy

### Current (Local Storage)

```
uploads/
â”œâ”€â”€ {uuid}.jpg              # User images
â”œâ”€â”€ voice_{uuid}.mp3        # Voice samples
â””â”€â”€ voices/
    â”œâ”€â”€ voice_{uuid}.mp3    # Generated voices
    â””â”€â”€ voice_cloned_{uuid}.mp3

generated_videos/
â””â”€â”€ {uuid}.mp4              # Generated videos
```

### Future (Cloud Storage)

```
Cloudflare R2 / AWS S3
â”œâ”€â”€ users/{user_id}/
â”‚   â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ voices/
â”‚   â””â”€â”€ videos/
â””â”€â”€ public/
    â””â”€â”€ videos/ (shareable links)
```

---

## ğŸ”„ Error Handling Strategy

### Frontend

```javascript
try {
    const response = await axios.post('/api/generate', data)
} catch (error) {
    if (error.response) {
        // Server responded with error
        alert(error.response.data.detail)
    } else if (error.request) {
        // No response from server
        alert('Server not responding')
    } else {
        // Other error
        alert('An error occurred')
    }
}
```

### Backend

```python
try:
    video_id = await sora_service.generate_video(...)
except Exception as e:
    logger.error(f"Video generation failed: {str(e)}")
    raise HTTPException(
        status_code=500,
        detail=f"Error generating video: {str(e)}"
    )
```

---

## ğŸ§ª Testing Strategy

### Unit Tests

```python
# Backend
pytest backend/tests/

test_sora_service.py
â”œâ”€â”€ test_generate_video()
â”œâ”€â”€ test_enhance_prompt()
â””â”€â”€ test_video_status()

test_voice_service.py
â”œâ”€â”€ test_generate_voice()
â””â”€â”€ test_clone_voice()
```

### Integration Tests

```python
# Full workflow test
test_video_generation_workflow.py
â”œâ”€â”€ test_upload_image()
â”œâ”€â”€ test_generate_suggestions()
â”œâ”€â”€ test_generate_video()
â””â”€â”€ test_download_video()
```

### E2E Tests (Frontend)

```javascript
// Playwright or Cypress
describe('Video Generation Flow', () => {
  it('should generate video from start to finish', () => {
    // Upload image
    // Enter prompt
    // Generate video
    // Download video
  })
})
```

---

## ğŸ”® Future Architecture Improvements

### Microservices (Scale)

```
API Gateway
â”œâ”€â”€ Video Service (Sora integration)
â”œâ”€â”€ Audio Service (Voice + Music)
â”œâ”€â”€ Suggestion Service (GPT-4)
â””â”€â”€ User Service (Auth, profiles)
```

### Message Queue

```
Frontend â†’ API â†’ RabbitMQ/Redis Queue
                      â†“
                  Worker Pool
                      â†“
                  Video Generation
```

### CDN Integration

```
User â†’ CloudFlare CDN â†’ Cached Video
                       â†“ (cache miss)
                   Origin Server
```

---

## ğŸ“ˆ Monitoring & Observability

### Metrics to Track

```
- Video generation success rate
- Average generation time
- API response times
- Error rates by endpoint
- User engagement metrics
- API costs per video
```

### Logging Strategy

```python
import logging

logger.info("Video generation started", extra={
    "video_id": video_id,
    "user_id": user_id,
    "prompt_length": len(prompt)
})

logger.error("Video generation failed", extra={
    "video_id": video_id,
    "error": str(e)
})
```

---

**Architecture Version:** 1.0.0
**Last Updated:** 2025-10-31
**Status:** MVP - Production Ready
